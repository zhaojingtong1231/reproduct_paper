{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenyizi/miniconda3/envs/Pyg2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from prompt_graph.tasker import NodeTask, GraphTask\n",
    "from prompt_graph.utils import seed_everything\n",
    "from torchsummary import summary\n",
    "from prompt_graph.utils import print_model_parameters\n",
    "from prompt_graph.utils import  get_args\n",
    "from prompt_graph.data import load4node,load4graph, split_induced_graphs\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can unzip the Experiment.zip to get the induced_graph file or run to get the induced_graph by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_induced_graph(dataset_name, data, device):\n",
    "\n",
    "    folder_path = './Experiment/induced_graph/' + dataset_name\n",
    "    if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    file_path = folder_path + '/induced_graph_min100_max300.pkl'\n",
    "    if os.path.exists(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                print('loading induced graph...')\n",
    "                graphs_list = pickle.load(f)\n",
    "                print('Done!!!')\n",
    "    else:\n",
    "        print('Begin split_induced_graphs.')\n",
    "        split_induced_graphs(data, folder_path, device, smallest_size=100, largest_size=300)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            graphs_list = pickle.load(f)\n",
    "    graphs_list = [graph.to(device) for graph in graphs_list]\n",
    "    return graphs_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_args:\n",
    "    task = 'NodeTask'  # 根据你的需求设置\n",
    "    dataset_name = 'Cora'\n",
    "    device = 3\n",
    "    gnn_type = 'GCN'\n",
    "    prompt_type = 'GPF-plus'\n",
    "    hid_dim = 128\n",
    "    batch_size = 128\n",
    "    epochs = 1000\n",
    "    shot_num = 1\n",
    "    pre_train_model_path = './Experiment/pre_trained_model/Cora/Edgepred_Gprompt.GCN.128hidden_dim.pth'\n",
    "    lr = 0.02\n",
    "    decay = 2e-6\n",
    "    num_layer = 2\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora\n",
      "loading induced graph...\n",
      "Done!!!\n",
      "GCN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GCNConv(1433, 128)\n",
      "    (1): GCNConv(128, 128)\n",
      "  )\n",
      ")\n",
      "Successfully loaded pre-trained weights!\n",
      "idx_train tensor([1144,   46,  451, 1279, 1370, 1942, 1451], device='cuda:3')\n",
      "true 1 tensor([1, 2, 5, 0, 6, 3, 4], device='cuda:3')\n",
      "distinguishing the train dataset and test dataset...\n",
      "Done!!!\n",
      "prepare induce graph data is finished!\n",
      "Epoch 001 |  Time(s) 0.2460 | Loss 1.9460  \n",
      "Epoch 002 |  Time(s) 0.0048 | Loss 1.9451  \n",
      "Epoch 003 |  Time(s) 0.0045 | Loss 1.9456  \n",
      "Epoch 004 |  Time(s) 0.0045 | Loss 1.9437  \n",
      "Epoch 005 |  Time(s) 0.0045 | Loss 1.9436  \n",
      "Epoch 006 |  Time(s) 0.0047 | Loss 1.9419  \n",
      "Epoch 007 |  Time(s) 0.0045 | Loss 1.9387  \n",
      "Epoch 008 |  Time(s) 0.0043 | Loss 1.9318  \n",
      "Epoch 009 |  Time(s) 0.0045 | Loss 1.9196  \n",
      "Epoch 010 |  Time(s) 0.0046 | Loss 1.9170  \n",
      "Epoch 011 |  Time(s) 0.0044 | Loss 1.9037  \n",
      "Epoch 012 |  Time(s) 0.0045 | Loss 1.8871  \n",
      "Epoch 013 |  Time(s) 0.0045 | Loss 1.8638  \n",
      "Epoch 014 |  Time(s) 0.0042 | Loss 1.8700  \n",
      "Epoch 015 |  Time(s) 0.0046 | Loss 1.8401  \n",
      "Epoch 016 |  Time(s) 0.0046 | Loss 1.8349  \n",
      "Epoch 017 |  Time(s) 0.0044 | Loss 1.8173  \n",
      "Epoch 018 |  Time(s) 0.0041 | Loss 1.8181  \n",
      "Epoch 019 |  Time(s) 0.0048 | Loss 1.8054  \n",
      "Epoch 020 |  Time(s) 0.0045 | Loss 1.8008  \n",
      "Epoch 021 |  Time(s) 0.0045 | Loss 1.7971  \n",
      "Epoch 022 |  Time(s) 0.0044 | Loss 1.7889  \n",
      "Epoch 023 |  Time(s) 0.0046 | Loss 1.7765  \n",
      "Epoch 024 |  Time(s) 0.0048 | Loss 1.7624  \n",
      "Epoch 025 |  Time(s) 0.0051 | Loss 1.7404  \n",
      "Epoch 026 |  Time(s) 0.0046 | Loss 1.7145  \n",
      "Epoch 027 |  Time(s) 0.0046 | Loss 1.6835  \n",
      "Epoch 028 |  Time(s) 0.0047 | Loss 1.6778  \n",
      "Epoch 029 |  Time(s) 0.0049 | Loss 1.6206  \n",
      "Epoch 030 |  Time(s) 0.0046 | Loss 1.6282  \n",
      "Epoch 031 |  Time(s) 0.0045 | Loss 1.6174  \n",
      "Epoch 032 |  Time(s) 0.0046 | Loss 1.5925  \n",
      "Epoch 033 |  Time(s) 0.0044 | Loss 1.5643  \n",
      "Epoch 034 |  Time(s) 0.0047 | Loss 1.5522  \n",
      "Epoch 035 |  Time(s) 0.0044 | Loss 1.5445  \n",
      "Epoch 036 |  Time(s) 0.0044 | Loss 1.5280  \n",
      "Epoch 037 |  Time(s) 0.0042 | Loss 1.5078  \n",
      "Epoch 038 |  Time(s) 0.0043 | Loss 1.5001  \n",
      "Epoch 039 |  Time(s) 0.0045 | Loss 1.4780  \n",
      "Epoch 040 |  Time(s) 0.0048 | Loss 1.4759  \n",
      "Epoch 041 |  Time(s) 0.0046 | Loss 1.4456  \n",
      "Epoch 042 |  Time(s) 0.0046 | Loss 1.4168  \n",
      "Epoch 043 |  Time(s) 0.0048 | Loss 1.3564  \n",
      "Epoch 044 |  Time(s) 0.0046 | Loss 1.3501  \n",
      "Epoch 045 |  Time(s) 0.0046 | Loss 1.3688  \n",
      "Epoch 046 |  Time(s) 0.0044 | Loss 1.3240  \n",
      "Epoch 047 |  Time(s) 0.0045 | Loss 1.3278  \n",
      "Epoch 048 |  Time(s) 0.0046 | Loss 1.3225  \n",
      "Epoch 049 |  Time(s) 0.0047 | Loss 1.3260  \n",
      "Epoch 050 |  Time(s) 0.0049 | Loss 1.3121  \n",
      "Epoch 051 |  Time(s) 0.0044 | Loss 1.3125  \n",
      "Epoch 052 |  Time(s) 0.0044 | Loss 1.3130  \n",
      "Epoch 053 |  Time(s) 0.0050 | Loss 1.3104  \n",
      "Epoch 054 |  Time(s) 0.0049 | Loss 1.3086  \n",
      "Epoch 055 |  Time(s) 0.0052 | Loss 1.3072  \n",
      "Epoch 056 |  Time(s) 0.0049 | Loss 1.3065  \n",
      "Epoch 057 |  Time(s) 0.0048 | Loss 1.3082  \n",
      "Epoch 058 |  Time(s) 0.0050 | Loss 1.3046  \n",
      "Epoch 059 |  Time(s) 0.0047 | Loss 1.3035  \n",
      "Epoch 060 |  Time(s) 0.0048 | Loss 1.3039  \n",
      "Epoch 061 |  Time(s) 0.0047 | Loss 1.3026  \n",
      "Epoch 062 |  Time(s) 0.0048 | Loss 1.3022  \n",
      "Epoch 063 |  Time(s) 0.0049 | Loss 1.3033  \n",
      "Epoch 064 |  Time(s) 0.0047 | Loss 1.3026  \n",
      "Epoch 065 |  Time(s) 0.0046 | Loss 1.3028  \n",
      "Epoch 066 |  Time(s) 0.0045 | Loss 1.3035  \n",
      "Epoch 067 |  Time(s) 0.0043 | Loss 1.3024  \n",
      "Epoch 068 |  Time(s) 0.0047 | Loss 1.3027  \n",
      "Epoch 069 |  Time(s) 0.0047 | Loss 1.3025  \n",
      "Epoch 070 |  Time(s) 0.0046 | Loss 1.3017  \n",
      "Epoch 071 |  Time(s) 0.0047 | Loss 1.3021  \n",
      "Epoch 072 |  Time(s) 0.0045 | Loss 1.3017  \n",
      "Epoch 073 |  Time(s) 0.0043 | Loss 1.3015  \n",
      "Epoch 074 |  Time(s) 0.0047 | Loss 1.3018  \n",
      "Epoch 075 |  Time(s) 0.0044 | Loss 1.3013  \n",
      "Epoch 076 |  Time(s) 0.0041 | Loss 1.3016  \n",
      "Epoch 077 |  Time(s) 0.0046 | Loss 1.3015  \n",
      "Epoch 078 |  Time(s) 0.0045 | Loss 1.3013  \n",
      "Epoch 079 |  Time(s) 0.0047 | Loss 1.3016  \n",
      "Epoch 080 |  Time(s) 0.0044 | Loss 1.3013  \n",
      "Epoch 081 |  Time(s) 0.0042 | Loss 1.3014  \n",
      "Epoch 082 |  Time(s) 0.0049 | Loss 1.3013  \n",
      "Epoch 083 |  Time(s) 0.0052 | Loss 1.3012  \n",
      "Epoch 084 |  Time(s) 0.0046 | Loss 1.3013  \n",
      "Epoch 085 |  Time(s) 0.0045 | Loss 1.3010  \n",
      "Epoch 086 |  Time(s) 0.0046 | Loss 1.3011  \n",
      "Epoch 087 |  Time(s) 0.0045 | Loss 1.3009  \n",
      "Epoch 088 |  Time(s) 0.0045 | Loss 1.3006  \n",
      "Epoch 089 |  Time(s) 0.0046 | Loss 1.3004  \n",
      "Epoch 090 |  Time(s) 0.0044 | Loss 1.3000  \n",
      "Epoch 091 |  Time(s) 0.0045 | Loss 1.2999  \n",
      "Epoch 092 |  Time(s) 0.0044 | Loss 1.3003  \n",
      "Epoch 093 |  Time(s) 0.0046 | Loss 1.3005  \n",
      "Epoch 094 |  Time(s) 0.0044 | Loss 1.3000  \n",
      "Epoch 095 |  Time(s) 0.0047 | Loss 1.2998  \n",
      "Epoch 096 |  Time(s) 0.0045 | Loss 1.2999  \n",
      "Epoch 097 |  Time(s) 0.0045 | Loss 1.3001  \n",
      "Epoch 098 |  Time(s) 0.0047 | Loss 1.3001  \n",
      "Epoch 099 |  Time(s) 0.0047 | Loss 1.3001  \n",
      "Epoch 100 |  Time(s) 0.0045 | Loss 1.2999  \n",
      "Epoch 101 |  Time(s) 0.0046 | Loss 1.2997  \n",
      "Epoch 102 |  Time(s) 0.0047 | Loss 1.2997  \n",
      "Epoch 103 |  Time(s) 0.0046 | Loss 1.2999  \n",
      "Epoch 104 |  Time(s) 0.0049 | Loss 1.2999  \n",
      "Epoch 105 |  Time(s) 0.0046 | Loss 1.2997  \n",
      "Epoch 106 |  Time(s) 0.0050 | Loss 1.2997  \n",
      "Epoch 107 |  Time(s) 0.0046 | Loss 1.2997  \n",
      "Epoch 108 |  Time(s) 0.0046 | Loss 1.2998  \n",
      "Epoch 109 |  Time(s) 0.0048 | Loss 1.2998  \n",
      "Epoch 110 |  Time(s) 0.0046 | Loss 1.2997  \n",
      "Epoch 111 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 112 |  Time(s) 0.0048 | Loss 1.2997  \n",
      "Epoch 113 |  Time(s) 0.0047 | Loss 1.2997  \n",
      "Epoch 114 |  Time(s) 0.0044 | Loss 1.2997  \n",
      "Epoch 115 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 116 |  Time(s) 0.0044 | Loss 1.2996  \n",
      "Epoch 117 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 118 |  Time(s) 0.0045 | Loss 1.2997  \n",
      "Epoch 119 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 120 |  Time(s) 0.0044 | Loss 1.2996  \n",
      "Epoch 121 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 122 |  Time(s) 0.0043 | Loss 1.2996  \n",
      "Epoch 123 |  Time(s) 0.0046 | Loss 1.2996  \n",
      "Epoch 124 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 125 |  Time(s) 0.0046 | Loss 1.2996  \n",
      "Epoch 126 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 127 |  Time(s) 0.0043 | Loss 1.2996  \n",
      "Epoch 128 |  Time(s) 0.0044 | Loss 1.2996  \n",
      "Epoch 129 |  Time(s) 0.0048 | Loss 1.2996  \n",
      "Epoch 130 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 131 |  Time(s) 0.0046 | Loss 1.2996  \n",
      "Epoch 132 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 133 |  Time(s) 0.0048 | Loss 1.2996  \n",
      "Epoch 134 |  Time(s) 0.0043 | Loss 1.2996  \n",
      "Epoch 135 |  Time(s) 0.0046 | Loss 1.2996  \n",
      "Epoch 136 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 137 |  Time(s) 0.0048 | Loss 1.2996  \n",
      "Epoch 138 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 139 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 140 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 141 |  Time(s) 0.0046 | Loss 1.2996  \n",
      "Epoch 142 |  Time(s) 0.0049 | Loss 1.2996  \n",
      "Epoch 143 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 144 |  Time(s) 0.0053 | Loss 1.2996  \n",
      "Epoch 145 |  Time(s) 0.0049 | Loss 1.2996  \n",
      "Epoch 146 |  Time(s) 0.0051 | Loss 1.2996  \n",
      "Epoch 147 |  Time(s) 0.0055 | Loss 1.2996  \n",
      "Epoch 148 |  Time(s) 0.0049 | Loss 1.2996  \n",
      "Epoch 149 |  Time(s) 0.0052 | Loss 1.2996  \n",
      "Epoch 150 |  Time(s) 0.0053 | Loss 1.2996  \n",
      "Epoch 151 |  Time(s) 0.0046 | Loss 1.2996  \n",
      "Epoch 152 |  Time(s) 0.0044 | Loss 1.2996  \n",
      "Epoch 153 |  Time(s) 0.0041 | Loss 1.2996  \n",
      "Epoch 154 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 155 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 156 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 157 |  Time(s) 0.0050 | Loss 1.2996  \n",
      "Epoch 158 |  Time(s) 0.0041 | Loss 1.2996  \n",
      "Epoch 159 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 160 |  Time(s) 0.0048 | Loss 1.2996  \n",
      "Epoch 161 |  Time(s) 0.0041 | Loss 1.2996  \n",
      "Epoch 162 |  Time(s) 0.0047 | Loss 1.2996  \n",
      "Epoch 163 |  Time(s) 0.0048 | Loss 1.2996  \n",
      "Epoch 164 |  Time(s) 0.0044 | Loss 1.2996  \n",
      "Epoch 165 |  Time(s) 0.0053 | Loss 1.2996  \n",
      "Epoch 166 |  Time(s) 0.0043 | Loss 1.2996  \n",
      "Epoch 167 |  Time(s) 0.0045 | Loss 1.2996  \n",
      "Epoch 168 |  Time(s) 0.0049 | Loss 1.2996  \n",
      "Epoch 169 |  Time(s) 0.0044 | Loss 1.2996  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping at 170 eopch!\n",
      "Final True Accuracy: 0.5012 | Macro F1 Score: 0.4613 | AUROC: 0.8533 | AUPRC: 0.6046\n",
      "best_loss [1.2995651960372925]\n",
      "GCN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GCNConv(1433, 128)\n",
      "    (1): GCNConv(128, 128)\n",
      "  )\n",
      ")\n",
      "Successfully loaded pre-trained weights!\n",
      "idx_train tensor([2352, 1136,  724,  234, 1279, 1470, 1479], device='cuda:3')\n",
      "true 2 tensor([4, 2, 6, 1, 0, 5, 3], device='cuda:3')\n",
      "distinguishing the train dataset and test dataset...\n",
      "Done!!!\n",
      "prepare induce graph data is finished!\n",
      "Epoch 001 |  Time(s) 0.0056 | Loss 1.9460  \n",
      "Epoch 002 |  Time(s) 0.0045 | Loss 1.9456  \n",
      "Epoch 003 |  Time(s) 0.0041 | Loss 1.9459  \n",
      "Epoch 004 |  Time(s) 0.0044 | Loss 1.9450  \n",
      "Epoch 005 |  Time(s) 0.0041 | Loss 1.9455  \n",
      "Epoch 006 |  Time(s) 0.0042 | Loss 1.9449  \n",
      "Epoch 007 |  Time(s) 0.0044 | Loss 1.9437  \n",
      "Epoch 008 |  Time(s) 0.0043 | Loss 1.9424  \n",
      "Epoch 009 |  Time(s) 0.0043 | Loss 1.9403  \n",
      "Epoch 010 |  Time(s) 0.0045 | Loss 1.9360  \n",
      "Epoch 011 |  Time(s) 0.0040 | Loss 1.9293  \n",
      "Epoch 012 |  Time(s) 0.0044 | Loss 1.9182  \n",
      "Epoch 013 |  Time(s) 0.0042 | Loss 1.9016  \n",
      "Epoch 014 |  Time(s) 0.0043 | Loss 1.8797  \n",
      "Epoch 015 |  Time(s) 0.0042 | Loss 1.9070  \n",
      "Epoch 016 |  Time(s) 0.0040 | Loss 1.8501  \n",
      "Epoch 017 |  Time(s) 0.0043 | Loss 1.9301  \n",
      "Epoch 018 |  Time(s) 0.0043 | Loss 1.8651  \n",
      "Epoch 019 |  Time(s) 0.0041 | Loss 1.8432  \n",
      "Epoch 020 |  Time(s) 0.0041 | Loss 1.8277  \n",
      "Epoch 021 |  Time(s) 0.0041 | Loss 1.7928  \n",
      "Epoch 022 |  Time(s) 0.0041 | Loss 1.7501  \n",
      "Epoch 023 |  Time(s) 0.0041 | Loss 1.7494  \n",
      "Epoch 024 |  Time(s) 0.0041 | Loss 1.6878  \n",
      "Epoch 025 |  Time(s) 0.0042 | Loss 1.6821  \n",
      "Epoch 026 |  Time(s) 0.0042 | Loss 1.6650  \n",
      "Epoch 027 |  Time(s) 0.0038 | Loss 1.6133  \n",
      "Epoch 028 |  Time(s) 0.0042 | Loss 1.6077  \n",
      "Epoch 029 |  Time(s) 0.0040 | Loss 1.5767  \n",
      "Epoch 030 |  Time(s) 0.0041 | Loss 1.5405  \n",
      "Epoch 031 |  Time(s) 0.0043 | Loss 1.5247  \n",
      "Epoch 032 |  Time(s) 0.0042 | Loss 1.4925  \n",
      "Epoch 033 |  Time(s) 0.0041 | Loss 1.4795  \n",
      "Epoch 034 |  Time(s) 0.0042 | Loss 1.4570  \n",
      "Epoch 035 |  Time(s) 0.0055 | Loss 1.4398  \n",
      "Epoch 036 |  Time(s) 0.0041 | Loss 1.4189  \n",
      "Epoch 037 |  Time(s) 0.0045 | Loss 1.3735  \n",
      "Epoch 038 |  Time(s) 0.0041 | Loss 1.3534  \n",
      "Epoch 039 |  Time(s) 0.0043 | Loss 1.3501  \n",
      "Epoch 040 |  Time(s) 0.0042 | Loss 1.3148  \n",
      "Epoch 041 |  Time(s) 0.0044 | Loss 1.2956  \n",
      "Epoch 042 |  Time(s) 0.0044 | Loss 1.2801  \n",
      "Epoch 043 |  Time(s) 0.0044 | Loss 1.2699  \n",
      "Epoch 044 |  Time(s) 0.0041 | Loss 1.2502  \n",
      "Epoch 045 |  Time(s) 0.0045 | Loss 1.2322  \n",
      "Epoch 046 |  Time(s) 0.0043 | Loss 1.2159  \n",
      "Epoch 047 |  Time(s) 0.0042 | Loss 1.2027  \n",
      "Epoch 048 |  Time(s) 0.0042 | Loss 1.1935  \n",
      "Epoch 049 |  Time(s) 0.0039 | Loss 1.1864  \n",
      "Epoch 050 |  Time(s) 0.0040 | Loss 1.1814  \n",
      "Epoch 051 |  Time(s) 0.0040 | Loss 1.1778  \n",
      "Epoch 052 |  Time(s) 0.0041 | Loss 1.1753  \n",
      "Epoch 053 |  Time(s) 0.0044 | Loss 1.1732  \n",
      "Epoch 054 |  Time(s) 0.0041 | Loss 1.1714  \n",
      "Epoch 055 |  Time(s) 0.0039 | Loss 1.1701  \n",
      "Epoch 056 |  Time(s) 0.0046 | Loss 1.1691  \n",
      "Epoch 057 |  Time(s) 0.0040 | Loss 1.1683  \n",
      "Epoch 058 |  Time(s) 0.0045 | Loss 1.1677  \n",
      "Epoch 059 |  Time(s) 0.0041 | Loss 1.1673  \n",
      "Epoch 060 |  Time(s) 0.0037 | Loss 1.1670  \n",
      "Epoch 061 |  Time(s) 0.0040 | Loss 1.1668  \n",
      "Epoch 062 |  Time(s) 0.0040 | Loss 1.1666  \n",
      "Epoch 063 |  Time(s) 0.0046 | Loss 1.1665  \n",
      "Epoch 064 |  Time(s) 0.0047 | Loss 1.1664  \n",
      "Epoch 065 |  Time(s) 0.0041 | Loss 1.1663  \n",
      "Epoch 066 |  Time(s) 0.0040 | Loss 1.1662  \n",
      "Epoch 067 |  Time(s) 0.0040 | Loss 1.1662  \n",
      "Epoch 068 |  Time(s) 0.0041 | Loss 1.1661  \n",
      "Epoch 069 |  Time(s) 0.0040 | Loss 1.1661  \n",
      "Epoch 070 |  Time(s) 0.0042 | Loss 1.1660  \n",
      "Epoch 071 |  Time(s) 0.0039 | Loss 1.1660  \n",
      "Epoch 072 |  Time(s) 0.0042 | Loss 1.1659  \n",
      "Epoch 073 |  Time(s) 0.0040 | Loss 1.1659  \n",
      "Epoch 074 |  Time(s) 0.0040 | Loss 1.1659  \n",
      "Epoch 075 |  Time(s) 0.0039 | Loss 1.1659  \n",
      "Epoch 076 |  Time(s) 0.0042 | Loss 1.1659  \n",
      "Epoch 077 |  Time(s) 0.0041 | Loss 1.1658  \n",
      "Epoch 078 |  Time(s) 0.0047 | Loss 1.1658  \n",
      "Epoch 079 |  Time(s) 0.0042 | Loss 1.1658  \n",
      "Epoch 080 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 081 |  Time(s) 0.0043 | Loss 1.1658  \n",
      "Epoch 082 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 083 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 084 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 085 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 086 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 087 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 088 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 089 |  Time(s) 0.0041 | Loss 1.1657  \n",
      "Epoch 090 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 091 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 092 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 093 |  Time(s) 0.0041 | Loss 1.1657  \n",
      "Epoch 094 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 095 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 096 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 097 |  Time(s) 0.0040 | Loss 1.1657  \n",
      "Epoch 098 |  Time(s) 0.0041 | Loss 1.1657  \n",
      "Epoch 099 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 100 |  Time(s) 0.0048 | Loss 1.1657  \n",
      "Epoch 101 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 102 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 103 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 104 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 105 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 106 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 107 |  Time(s) 0.0046 | Loss 1.1657  \n",
      "Epoch 108 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 109 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 110 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 111 |  Time(s) 0.0046 | Loss 1.1657  \n",
      "Epoch 112 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 113 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 114 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 115 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 116 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 117 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 118 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 119 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 120 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 121 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 122 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 123 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 124 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping at 125 eopch!\n",
      "Final True Accuracy: 0.4056 | Macro F1 Score: 0.4077 | AUROC: 0.8173 | AUPRC: 0.4687\n",
      "best_loss [1.2995651960372925, 1.1656675338745117]\n",
      "GCN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GCNConv(1433, 128)\n",
      "    (1): GCNConv(128, 128)\n",
      "  )\n",
      ")\n",
      "Successfully loaded pre-trained weights!\n",
      "idx_train tensor([1009, 1291, 1118, 1635, 2185, 1577,  355], device='cuda:3')\n",
      "true 3 tensor([1, 6, 0, 4, 5, 3, 2], device='cuda:3')\n",
      "distinguishing the train dataset and test dataset...\n",
      "Done!!!\n",
      "prepare induce graph data is finished!\n",
      "Epoch 001 |  Time(s) 0.0061 | Loss 1.9459  \n",
      "Epoch 002 |  Time(s) 0.0042 | Loss 1.9453  \n",
      "Epoch 003 |  Time(s) 0.0041 | Loss 1.9460  \n",
      "Epoch 004 |  Time(s) 0.0043 | Loss 1.9450  \n",
      "Epoch 005 |  Time(s) 0.0040 | Loss 1.9450  \n",
      "Epoch 006 |  Time(s) 0.0038 | Loss 1.9448  \n",
      "Epoch 007 |  Time(s) 0.0049 | Loss 1.9432  \n",
      "Epoch 008 |  Time(s) 0.0054 | Loss 1.9399  \n",
      "Epoch 009 |  Time(s) 0.0080 | Loss 1.9350  \n",
      "Epoch 010 |  Time(s) 0.0051 | Loss 1.9254  \n",
      "Epoch 011 |  Time(s) 0.0074 | Loss 1.9221  \n",
      "Epoch 012 |  Time(s) 0.0051 | Loss 1.9421  \n",
      "Epoch 013 |  Time(s) 0.0047 | Loss 1.9075  \n",
      "Epoch 014 |  Time(s) 0.0046 | Loss 1.9165  \n",
      "Epoch 015 |  Time(s) 0.0046 | Loss 1.8986  \n",
      "Epoch 016 |  Time(s) 0.0044 | Loss 1.8795  \n",
      "Epoch 017 |  Time(s) 0.0044 | Loss 1.8840  \n",
      "Epoch 018 |  Time(s) 0.0045 | Loss 1.8384  \n",
      "Epoch 019 |  Time(s) 0.0045 | Loss 1.8610  \n",
      "Epoch 020 |  Time(s) 0.0044 | Loss 1.8068  \n",
      "Epoch 021 |  Time(s) 0.0044 | Loss 1.8265  \n",
      "Epoch 022 |  Time(s) 0.0045 | Loss 1.7753  \n",
      "Epoch 023 |  Time(s) 0.0048 | Loss 1.7812  \n",
      "Epoch 024 |  Time(s) 0.0048 | Loss 1.7413  \n",
      "Epoch 025 |  Time(s) 0.0046 | Loss 1.7401  \n",
      "Epoch 026 |  Time(s) 0.0044 | Loss 1.7063  \n",
      "Epoch 027 |  Time(s) 0.0044 | Loss 1.7097  \n",
      "Epoch 028 |  Time(s) 0.0044 | Loss 1.6821  \n",
      "Epoch 029 |  Time(s) 0.0042 | Loss 1.6843  \n",
      "Epoch 030 |  Time(s) 0.0044 | Loss 1.6639  \n",
      "Epoch 031 |  Time(s) 0.0046 | Loss 1.6444  \n",
      "Epoch 032 |  Time(s) 0.0045 | Loss 1.6364  \n",
      "Epoch 033 |  Time(s) 0.0045 | Loss 1.6063  \n",
      "Epoch 034 |  Time(s) 0.0046 | Loss 1.5983  \n",
      "Epoch 035 |  Time(s) 0.0045 | Loss 1.5680  \n",
      "Epoch 036 |  Time(s) 0.0049 | Loss 1.5584  \n",
      "Epoch 037 |  Time(s) 0.0051 | Loss 1.5182  \n",
      "Epoch 038 |  Time(s) 0.0044 | Loss 1.4819  \n",
      "Epoch 039 |  Time(s) 0.0045 | Loss 1.4576  \n",
      "Epoch 040 |  Time(s) 0.0044 | Loss 1.4408  \n",
      "Epoch 041 |  Time(s) 0.0052 | Loss 1.4237  \n",
      "Epoch 042 |  Time(s) 0.0045 | Loss 1.3808  \n",
      "Epoch 043 |  Time(s) 0.0046 | Loss 1.3611  \n",
      "Epoch 044 |  Time(s) 0.0066 | Loss 1.3364  \n",
      "Epoch 045 |  Time(s) 0.0049 | Loss 1.3151  \n",
      "Epoch 046 |  Time(s) 0.0047 | Loss 1.2824  \n",
      "Epoch 047 |  Time(s) 0.0045 | Loss 1.2728  \n",
      "Epoch 048 |  Time(s) 0.0045 | Loss 1.2568  \n",
      "Epoch 049 |  Time(s) 0.0046 | Loss 1.2313  \n",
      "Epoch 050 |  Time(s) 0.0044 | Loss 1.2216  \n",
      "Epoch 051 |  Time(s) 0.0045 | Loss 1.2139  \n",
      "Epoch 052 |  Time(s) 0.0044 | Loss 1.2036  \n",
      "Epoch 053 |  Time(s) 0.0044 | Loss 1.1961  \n",
      "Epoch 054 |  Time(s) 0.0046 | Loss 1.1879  \n",
      "Epoch 055 |  Time(s) 0.0047 | Loss 1.1841  \n",
      "Epoch 056 |  Time(s) 0.0044 | Loss 1.1827  \n",
      "Epoch 057 |  Time(s) 0.0045 | Loss 1.1807  \n",
      "Epoch 058 |  Time(s) 0.0048 | Loss 1.1776  \n",
      "Epoch 059 |  Time(s) 0.0047 | Loss 1.1748  \n",
      "Epoch 060 |  Time(s) 0.0047 | Loss 1.1730  \n",
      "Epoch 061 |  Time(s) 0.0047 | Loss 1.1718  \n",
      "Epoch 062 |  Time(s) 0.0047 | Loss 1.1710  \n",
      "Epoch 063 |  Time(s) 0.0047 | Loss 1.1703  \n",
      "Epoch 064 |  Time(s) 0.0044 | Loss 1.1697  \n",
      "Epoch 065 |  Time(s) 0.0048 | Loss 1.1691  \n",
      "Epoch 066 |  Time(s) 0.0043 | Loss 1.1687  \n",
      "Epoch 067 |  Time(s) 0.0045 | Loss 1.1683  \n",
      "Epoch 068 |  Time(s) 0.0043 | Loss 1.1680  \n",
      "Epoch 069 |  Time(s) 0.0045 | Loss 1.1677  \n",
      "Epoch 070 |  Time(s) 0.0047 | Loss 1.1674  \n",
      "Epoch 071 |  Time(s) 0.0047 | Loss 1.1671  \n",
      "Epoch 072 |  Time(s) 0.0046 | Loss 1.1669  \n",
      "Epoch 073 |  Time(s) 0.0044 | Loss 1.1668  \n",
      "Epoch 074 |  Time(s) 0.0048 | Loss 1.1666  \n",
      "Epoch 075 |  Time(s) 0.0045 | Loss 1.1665  \n",
      "Epoch 076 |  Time(s) 0.0046 | Loss 1.1665  \n",
      "Epoch 077 |  Time(s) 0.0045 | Loss 1.1664  \n",
      "Epoch 078 |  Time(s) 0.0045 | Loss 1.1664  \n",
      "Epoch 079 |  Time(s) 0.0045 | Loss 1.1663  \n",
      "Epoch 080 |  Time(s) 0.0085 | Loss 1.1663  \n",
      "Epoch 081 |  Time(s) 0.0049 | Loss 1.1663  \n",
      "Epoch 082 |  Time(s) 0.0048 | Loss 1.1662  \n",
      "Epoch 083 |  Time(s) 0.0043 | Loss 1.1662  \n",
      "Epoch 084 |  Time(s) 0.0047 | Loss 1.1662  \n",
      "Epoch 085 |  Time(s) 0.0046 | Loss 1.1661  \n",
      "Epoch 086 |  Time(s) 0.0046 | Loss 1.1661  \n",
      "Epoch 087 |  Time(s) 0.0047 | Loss 1.1661  \n",
      "Epoch 088 |  Time(s) 0.0048 | Loss 1.1661  \n",
      "Epoch 089 |  Time(s) 0.0046 | Loss 1.1661  \n",
      "Epoch 090 |  Time(s) 0.0045 | Loss 1.1660  \n",
      "Epoch 091 |  Time(s) 0.0046 | Loss 1.1660  \n",
      "Epoch 092 |  Time(s) 0.0046 | Loss 1.1660  \n",
      "Epoch 093 |  Time(s) 0.0044 | Loss 1.1660  \n",
      "Epoch 094 |  Time(s) 0.0045 | Loss 1.1660  \n",
      "Epoch 095 |  Time(s) 0.0045 | Loss 1.1660  \n",
      "Epoch 096 |  Time(s) 0.0046 | Loss 1.1660  \n",
      "Epoch 097 |  Time(s) 0.0044 | Loss 1.1660  \n",
      "Epoch 098 |  Time(s) 0.0044 | Loss 1.1659  \n",
      "Epoch 099 |  Time(s) 0.0045 | Loss 1.1659  \n",
      "Epoch 100 |  Time(s) 0.0046 | Loss 1.1659  \n",
      "Epoch 101 |  Time(s) 0.0042 | Loss 1.1659  \n",
      "Epoch 102 |  Time(s) 0.0042 | Loss 1.1659  \n",
      "Epoch 103 |  Time(s) 0.0045 | Loss 1.1659  \n",
      "Epoch 104 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 105 |  Time(s) 0.0044 | Loss 1.1659  \n",
      "Epoch 106 |  Time(s) 0.0045 | Loss 1.1659  \n",
      "Epoch 107 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 108 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 109 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 110 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 111 |  Time(s) 0.0046 | Loss 1.1659  \n",
      "Epoch 112 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 113 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 114 |  Time(s) 0.0079 | Loss 1.1659  \n",
      "Epoch 115 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 116 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 117 |  Time(s) 0.0050 | Loss 1.1659  \n",
      "Epoch 118 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 119 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 120 |  Time(s) 0.0046 | Loss 1.1659  \n",
      "Epoch 121 |  Time(s) 0.0049 | Loss 1.1659  \n",
      "Epoch 122 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 123 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 124 |  Time(s) 0.0045 | Loss 1.1659  \n",
      "Epoch 125 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 126 |  Time(s) 0.0046 | Loss 1.1659  \n",
      "Epoch 127 |  Time(s) 0.0049 | Loss 1.1659  \n",
      "Epoch 128 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 129 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 130 |  Time(s) 0.0045 | Loss 1.1659  \n",
      "Epoch 131 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 132 |  Time(s) 0.0049 | Loss 1.1659  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping at 133 eopch!\n",
      "Final True Accuracy: 0.3122 | Macro F1 Score: 0.2469 | AUROC: 0.8150 | AUPRC: 0.4654\n",
      "best_loss [1.2995651960372925, 1.1656675338745117, 1.1659355163574219]\n",
      "GCN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GCNConv(1433, 128)\n",
      "    (1): GCNConv(128, 128)\n",
      "  )\n",
      ")\n",
      "Successfully loaded pre-trained weights!\n",
      "idx_train tensor([1971,  494, 2575, 1253,   23, 1960, 1948], device='cuda:3')\n",
      "true 4 tensor([4, 2, 0, 1, 6, 5, 3], device='cuda:3')\n",
      "distinguishing the train dataset and test dataset...\n",
      "Done!!!\n",
      "prepare induce graph data is finished!\n",
      "Epoch 001 |  Time(s) 0.0063 | Loss 1.9459  \n",
      "Epoch 002 |  Time(s) 0.0049 | Loss 1.9452  \n",
      "Epoch 003 |  Time(s) 0.0049 | Loss 1.9446  \n",
      "Epoch 004 |  Time(s) 0.0047 | Loss 1.9487  \n",
      "Epoch 005 |  Time(s) 0.0050 | Loss 1.9444  \n",
      "Epoch 006 |  Time(s) 0.0050 | Loss 1.9460  \n",
      "Epoch 007 |  Time(s) 0.0053 | Loss 1.9457  \n",
      "Epoch 008 |  Time(s) 0.0052 | Loss 1.9450  \n",
      "Epoch 009 |  Time(s) 0.0049 | Loss 1.9445  \n",
      "Epoch 010 |  Time(s) 0.0050 | Loss 1.9436  \n",
      "Epoch 011 |  Time(s) 0.0049 | Loss 1.9417  \n",
      "Epoch 012 |  Time(s) 0.0052 | Loss 1.9389  \n",
      "Epoch 013 |  Time(s) 0.0047 | Loss 1.9345  \n",
      "Epoch 014 |  Time(s) 0.0048 | Loss 1.9272  \n",
      "Epoch 015 |  Time(s) 0.0047 | Loss 1.9155  \n",
      "Epoch 016 |  Time(s) 0.0049 | Loss 1.8959  \n",
      "Epoch 017 |  Time(s) 0.0047 | Loss 1.8686  \n",
      "Epoch 018 |  Time(s) 0.0047 | Loss 1.8337  \n",
      "Epoch 019 |  Time(s) 0.0049 | Loss 1.7993  \n",
      "Epoch 020 |  Time(s) 0.0042 | Loss 1.7808  \n",
      "Epoch 021 |  Time(s) 0.0048 | Loss 1.7840  \n",
      "Epoch 022 |  Time(s) 0.0047 | Loss 1.7416  \n",
      "Epoch 023 |  Time(s) 0.0047 | Loss 1.7337  \n",
      "Epoch 024 |  Time(s) 0.0047 | Loss 1.7041  \n",
      "Epoch 025 |  Time(s) 0.0050 | Loss 1.6723  \n",
      "Epoch 026 |  Time(s) 0.0048 | Loss 1.6549  \n",
      "Epoch 027 |  Time(s) 0.0043 | Loss 1.6221  \n",
      "Epoch 028 |  Time(s) 0.0048 | Loss 1.6136  \n",
      "Epoch 029 |  Time(s) 0.0047 | Loss 1.5694  \n",
      "Epoch 030 |  Time(s) 0.0049 | Loss 1.5519  \n",
      "Epoch 031 |  Time(s) 0.0044 | Loss 1.5575  \n",
      "Epoch 032 |  Time(s) 0.0048 | Loss 1.5094  \n",
      "Epoch 033 |  Time(s) 0.0046 | Loss 1.5000  \n",
      "Epoch 034 |  Time(s) 0.0046 | Loss 1.4754  \n",
      "Epoch 035 |  Time(s) 0.0039 | Loss 1.4361  \n",
      "Epoch 036 |  Time(s) 0.0047 | Loss 1.4182  \n",
      "Epoch 037 |  Time(s) 0.0046 | Loss 1.3938  \n",
      "Epoch 038 |  Time(s) 0.0044 | Loss 1.3883  \n",
      "Epoch 039 |  Time(s) 0.0047 | Loss 1.3529  \n",
      "Epoch 040 |  Time(s) 0.0044 | Loss 1.3370  \n",
      "Epoch 041 |  Time(s) 0.0047 | Loss 1.3167  \n",
      "Epoch 042 |  Time(s) 0.0046 | Loss 1.3008  \n",
      "Epoch 043 |  Time(s) 0.0045 | Loss 1.2697  \n",
      "Epoch 044 |  Time(s) 0.0045 | Loss 1.2626  \n",
      "Epoch 045 |  Time(s) 0.0045 | Loss 1.2428  \n",
      "Epoch 046 |  Time(s) 0.0045 | Loss 1.2164  \n",
      "Epoch 047 |  Time(s) 0.0046 | Loss 1.2042  \n",
      "Epoch 048 |  Time(s) 0.0052 | Loss 1.1976  \n",
      "Epoch 049 |  Time(s) 0.0050 | Loss 1.1858  \n",
      "Epoch 050 |  Time(s) 0.0049 | Loss 1.1800  \n",
      "Epoch 051 |  Time(s) 0.0045 | Loss 1.1762  \n",
      "Epoch 052 |  Time(s) 0.0046 | Loss 1.1723  \n",
      "Epoch 053 |  Time(s) 0.0097 | Loss 1.1700  \n",
      "Epoch 054 |  Time(s) 0.0050 | Loss 1.1691  \n",
      "Epoch 055 |  Time(s) 0.0046 | Loss 1.1686  \n",
      "Epoch 056 |  Time(s) 0.0049 | Loss 1.1683  \n",
      "Epoch 057 |  Time(s) 0.0047 | Loss 1.1680  \n",
      "Epoch 058 |  Time(s) 0.0046 | Loss 1.1675  \n",
      "Epoch 059 |  Time(s) 0.0048 | Loss 1.1670  \n",
      "Epoch 060 |  Time(s) 0.0050 | Loss 1.1666  \n",
      "Epoch 061 |  Time(s) 0.0049 | Loss 1.1663  \n",
      "Epoch 062 |  Time(s) 0.0045 | Loss 1.1661  \n",
      "Epoch 063 |  Time(s) 0.0051 | Loss 1.1659  \n",
      "Epoch 064 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 065 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 066 |  Time(s) 0.0043 | Loss 1.1658  \n",
      "Epoch 067 |  Time(s) 0.0046 | Loss 1.1658  \n",
      "Epoch 068 |  Time(s) 0.0049 | Loss 1.1658  \n",
      "Epoch 069 |  Time(s) 0.0046 | Loss 1.1658  \n",
      "Epoch 070 |  Time(s) 0.0048 | Loss 1.1657  \n",
      "Epoch 071 |  Time(s) 0.0047 | Loss 1.1657  \n",
      "Epoch 072 |  Time(s) 0.0056 | Loss 1.1657  \n",
      "Epoch 073 |  Time(s) 0.0048 | Loss 1.1657  \n",
      "Epoch 074 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 075 |  Time(s) 0.0050 | Loss 1.1657  \n",
      "Epoch 076 |  Time(s) 0.0047 | Loss 1.1657  \n",
      "Epoch 077 |  Time(s) 0.0047 | Loss 1.1657  \n",
      "Epoch 078 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 079 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 080 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 081 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 082 |  Time(s) 0.0050 | Loss 1.1656  \n",
      "Epoch 083 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 084 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 085 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 086 |  Time(s) 0.0044 | Loss 1.1656  \n",
      "Epoch 087 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 088 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 089 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 090 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 091 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 092 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 093 |  Time(s) 0.0045 | Loss 1.1656  \n",
      "Epoch 094 |  Time(s) 0.0043 | Loss 1.1656  \n",
      "Epoch 095 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 096 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 097 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 098 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 099 |  Time(s) 0.0045 | Loss 1.1656  \n",
      "Epoch 100 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 101 |  Time(s) 0.0045 | Loss 1.1656  \n",
      "Epoch 102 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 103 |  Time(s) 0.0046 | Loss 1.1656  \n",
      "Epoch 104 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 105 |  Time(s) 0.0045 | Loss 1.1656  \n",
      "Epoch 106 |  Time(s) 0.0053 | Loss 1.1656  \n",
      "Epoch 107 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 108 |  Time(s) 0.0050 | Loss 1.1656  \n",
      "Epoch 109 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 110 |  Time(s) 0.0050 | Loss 1.1656  \n",
      "Epoch 111 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 112 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 113 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 114 |  Time(s) 0.0050 | Loss 1.1656  \n",
      "Epoch 115 |  Time(s) 0.0051 | Loss 1.1656  \n",
      "Epoch 116 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 117 |  Time(s) 0.0048 | Loss 1.1656  \n",
      "Epoch 118 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 119 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 120 |  Time(s) 0.0096 | Loss 1.1656  \n",
      "Epoch 121 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 122 |  Time(s) 0.0051 | Loss 1.1656  \n",
      "Epoch 123 |  Time(s) 0.0051 | Loss 1.1656  \n",
      "Epoch 124 |  Time(s) 0.0049 | Loss 1.1656  \n",
      "Epoch 125 |  Time(s) 0.0047 | Loss 1.1656  \n",
      "Epoch 126 |  Time(s) 0.0051 | Loss 1.1656  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping at 127 eopch!\n",
      "Final True Accuracy: 0.5837 | Macro F1 Score: 0.5026 | AUROC: 0.8593 | AUPRC: 0.6231\n",
      "best_loss [1.2995651960372925, 1.1656675338745117, 1.1659355163574219, 1.1656014919281006]\n",
      "GCN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GCNConv(1433, 128)\n",
      "    (1): GCNConv(128, 128)\n",
      "  )\n",
      ")\n",
      "Successfully loaded pre-trained weights!\n",
      "idx_train tensor([ 234, 1291,  258,    5,  803, 2035, 2333], device='cuda:3')\n",
      "true 5 tensor([1, 6, 4, 2, 5, 3, 0], device='cuda:3')\n",
      "distinguishing the train dataset and test dataset...\n",
      "Done!!!\n",
      "prepare induce graph data is finished!\n",
      "Epoch 001 |  Time(s) 0.0057 | Loss 1.9460  \n",
      "Epoch 002 |  Time(s) 0.0049 | Loss 1.9456  \n",
      "Epoch 003 |  Time(s) 0.0049 | Loss 1.9454  \n",
      "Epoch 004 |  Time(s) 0.0049 | Loss 1.9452  \n",
      "Epoch 005 |  Time(s) 0.0048 | Loss 1.9450  \n",
      "Epoch 006 |  Time(s) 0.0046 | Loss 1.9444  \n",
      "Epoch 007 |  Time(s) 0.0048 | Loss 1.9436  \n",
      "Epoch 008 |  Time(s) 0.0050 | Loss 1.9419  \n",
      "Epoch 009 |  Time(s) 0.0048 | Loss 1.9390  \n",
      "Epoch 010 |  Time(s) 0.0046 | Loss 1.9337  \n",
      "Epoch 011 |  Time(s) 0.0047 | Loss 1.9256  \n",
      "Epoch 012 |  Time(s) 0.0047 | Loss 1.9131  \n",
      "Epoch 013 |  Time(s) 0.0050 | Loss 1.8958  \n",
      "Epoch 014 |  Time(s) 0.0049 | Loss 1.8838  \n",
      "Epoch 015 |  Time(s) 0.0043 | Loss 1.8665  \n",
      "Epoch 016 |  Time(s) 0.0050 | Loss 1.8554  \n",
      "Epoch 017 |  Time(s) 0.0047 | Loss 1.8181  \n",
      "Epoch 018 |  Time(s) 0.0048 | Loss 1.8116  \n",
      "Epoch 019 |  Time(s) 0.0047 | Loss 1.7755  \n",
      "Epoch 020 |  Time(s) 0.0049 | Loss 1.7374  \n",
      "Epoch 021 |  Time(s) 0.0048 | Loss 1.7120  \n",
      "Epoch 022 |  Time(s) 0.0046 | Loss 1.6582  \n",
      "Epoch 023 |  Time(s) 0.0048 | Loss 1.6604  \n",
      "Epoch 024 |  Time(s) 0.0049 | Loss 1.6223  \n",
      "Epoch 025 |  Time(s) 0.0048 | Loss 1.5933  \n",
      "Epoch 026 |  Time(s) 0.0050 | Loss 1.5578  \n",
      "Epoch 027 |  Time(s) 0.0047 | Loss 1.5497  \n",
      "Epoch 028 |  Time(s) 0.0045 | Loss 1.5147  \n",
      "Epoch 029 |  Time(s) 0.0048 | Loss 1.4932  \n",
      "Epoch 030 |  Time(s) 0.0044 | Loss 1.4637  \n",
      "Epoch 031 |  Time(s) 0.0044 | Loss 1.4499  \n",
      "Epoch 032 |  Time(s) 0.0045 | Loss 1.4206  \n",
      "Epoch 033 |  Time(s) 0.0045 | Loss 1.3880  \n",
      "Epoch 034 |  Time(s) 0.0046 | Loss 1.3756  \n",
      "Epoch 035 |  Time(s) 0.0043 | Loss 1.3527  \n",
      "Epoch 036 |  Time(s) 0.0044 | Loss 1.3268  \n",
      "Epoch 037 |  Time(s) 0.0045 | Loss 1.3090  \n",
      "Epoch 038 |  Time(s) 0.0047 | Loss 1.2774  \n",
      "Epoch 039 |  Time(s) 0.0046 | Loss 1.2689  \n",
      "Epoch 040 |  Time(s) 0.0049 | Loss 1.2628  \n",
      "Epoch 041 |  Time(s) 0.0040 | Loss 1.2412  \n",
      "Epoch 042 |  Time(s) 0.0046 | Loss 1.2230  \n",
      "Epoch 043 |  Time(s) 0.0048 | Loss 1.2108  \n",
      "Epoch 044 |  Time(s) 0.0045 | Loss 1.2002  \n",
      "Epoch 045 |  Time(s) 0.0050 | Loss 1.1912  \n",
      "Epoch 046 |  Time(s) 0.0055 | Loss 1.1833  \n",
      "Epoch 047 |  Time(s) 0.0049 | Loss 1.1783  \n",
      "Epoch 048 |  Time(s) 0.0044 | Loss 1.1758  \n",
      "Epoch 049 |  Time(s) 0.0046 | Loss 1.1754  \n",
      "Epoch 050 |  Time(s) 0.0047 | Loss 1.1750  \n",
      "Epoch 051 |  Time(s) 0.0047 | Loss 1.1732  \n",
      "Epoch 052 |  Time(s) 0.0051 | Loss 1.1713  \n",
      "Epoch 053 |  Time(s) 0.0047 | Loss 1.1703  \n",
      "Epoch 054 |  Time(s) 0.0047 | Loss 1.1701  \n",
      "Epoch 055 |  Time(s) 0.0046 | Loss 1.1701  \n",
      "Epoch 056 |  Time(s) 0.0048 | Loss 1.1700  \n",
      "Epoch 057 |  Time(s) 0.0092 | Loss 1.1696  \n",
      "Epoch 058 |  Time(s) 0.0046 | Loss 1.1689  \n",
      "Epoch 059 |  Time(s) 0.0047 | Loss 1.1684  \n",
      "Epoch 060 |  Time(s) 0.0049 | Loss 1.1680  \n",
      "Epoch 061 |  Time(s) 0.0046 | Loss 1.1679  \n",
      "Epoch 062 |  Time(s) 0.0050 | Loss 1.1678  \n",
      "Epoch 063 |  Time(s) 0.0047 | Loss 1.1678  \n",
      "Epoch 064 |  Time(s) 0.0043 | Loss 1.1676  \n",
      "Epoch 065 |  Time(s) 0.0045 | Loss 1.1673  \n",
      "Epoch 066 |  Time(s) 0.0045 | Loss 1.1670  \n",
      "Epoch 067 |  Time(s) 0.0045 | Loss 1.1668  \n",
      "Epoch 068 |  Time(s) 0.0054 | Loss 1.1666  \n",
      "Epoch 069 |  Time(s) 0.0049 | Loss 1.1665  \n",
      "Epoch 070 |  Time(s) 0.0047 | Loss 1.1665  \n",
      "Epoch 071 |  Time(s) 0.0047 | Loss 1.1664  \n",
      "Epoch 072 |  Time(s) 0.0047 | Loss 1.1664  \n",
      "Epoch 073 |  Time(s) 0.0046 | Loss 1.1663  \n",
      "Epoch 074 |  Time(s) 0.0048 | Loss 1.1663  \n",
      "Epoch 075 |  Time(s) 0.0048 | Loss 1.1663  \n",
      "Epoch 076 |  Time(s) 0.0045 | Loss 1.1662  \n",
      "Epoch 077 |  Time(s) 0.0042 | Loss 1.1662  \n",
      "Epoch 078 |  Time(s) 0.0048 | Loss 1.1661  \n",
      "Epoch 079 |  Time(s) 0.0046 | Loss 1.1661  \n",
      "Epoch 080 |  Time(s) 0.0048 | Loss 1.1660  \n",
      "Epoch 081 |  Time(s) 0.0051 | Loss 1.1660  \n",
      "Epoch 082 |  Time(s) 0.0050 | Loss 1.1660  \n",
      "Epoch 083 |  Time(s) 0.0046 | Loss 1.1660  \n",
      "Epoch 084 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 085 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 086 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 087 |  Time(s) 0.0049 | Loss 1.1659  \n",
      "Epoch 088 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 089 |  Time(s) 0.0047 | Loss 1.1659  \n",
      "Epoch 090 |  Time(s) 0.0049 | Loss 1.1659  \n",
      "Epoch 091 |  Time(s) 0.0048 | Loss 1.1659  \n",
      "Epoch 092 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 093 |  Time(s) 0.0044 | Loss 1.1658  \n",
      "Epoch 094 |  Time(s) 0.0047 | Loss 1.1658  \n",
      "Epoch 095 |  Time(s) 0.0046 | Loss 1.1658  \n",
      "Epoch 096 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 097 |  Time(s) 0.0044 | Loss 1.1658  \n",
      "Epoch 098 |  Time(s) 0.0047 | Loss 1.1658  \n",
      "Epoch 099 |  Time(s) 0.0047 | Loss 1.1658  \n",
      "Epoch 100 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 101 |  Time(s) 0.0049 | Loss 1.1658  \n",
      "Epoch 102 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 103 |  Time(s) 0.0053 | Loss 1.1658  \n",
      "Epoch 104 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 105 |  Time(s) 0.0049 | Loss 1.1658  \n",
      "Epoch 106 |  Time(s) 0.0047 | Loss 1.1658  \n",
      "Epoch 107 |  Time(s) 0.0051 | Loss 1.1658  \n",
      "Epoch 108 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 109 |  Time(s) 0.0050 | Loss 1.1658  \n",
      "Epoch 110 |  Time(s) 0.0051 | Loss 1.1658  \n",
      "Epoch 111 |  Time(s) 0.0048 | Loss 1.1658  \n",
      "Epoch 112 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 113 |  Time(s) 0.0049 | Loss 1.1658  \n",
      "Epoch 114 |  Time(s) 0.0050 | Loss 1.1658  \n",
      "Epoch 115 |  Time(s) 0.0049 | Loss 1.1658  \n",
      "Epoch 116 |  Time(s) 0.0050 | Loss 1.1658  \n",
      "Epoch 117 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 118 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 119 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 120 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 121 |  Time(s) 0.0041 | Loss 1.1657  \n",
      "Epoch 122 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 123 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 124 |  Time(s) 0.0047 | Loss 1.1657  \n",
      "Epoch 125 |  Time(s) 0.0048 | Loss 1.1657  \n",
      "Epoch 126 |  Time(s) 0.0042 | Loss 1.1657  \n",
      "Epoch 127 |  Time(s) 0.0041 | Loss 1.1657  \n",
      "Epoch 128 |  Time(s) 0.0089 | Loss 1.1657  \n",
      "Epoch 129 |  Time(s) 0.0046 | Loss 1.1657  \n",
      "Epoch 130 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 131 |  Time(s) 0.0043 | Loss 1.1657  \n",
      "Epoch 132 |  Time(s) 0.0046 | Loss 1.1657  \n",
      "Epoch 133 |  Time(s) 0.0044 | Loss 1.1657  \n",
      "Epoch 134 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 135 |  Time(s) 0.0046 | Loss 1.1657  \n",
      "Epoch 136 |  Time(s) 0.0045 | Loss 1.1657  \n",
      "Epoch 137 |  Time(s) 0.0039 | Loss 1.1657  \n",
      "Epoch 138 |  Time(s) 0.0046 | Loss 1.1658  \n",
      "Epoch 139 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 140 |  Time(s) 0.0044 | Loss 1.1658  \n",
      "Epoch 141 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 142 |  Time(s) 0.0044 | Loss 1.1658  \n",
      "Epoch 143 |  Time(s) 0.0045 | Loss 1.1658  \n",
      "Epoch 144 |  Time(s) 0.0046 | Loss 1.1658  \n",
      "Epoch 145 |  Time(s) 0.0049 | Loss 1.1658  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stopping at 146 eopch!\n",
      "Final True Accuracy: 0.5985 | Macro F1 Score: 0.5335 | AUROC: 0.8851 | AUPRC: 0.5987\n",
      "best_loss [1.2995651960372925, 1.1656675338745117, 1.1659355163574219, 1.1656014919281006, 1.1657551527023315]\n",
      " Final best | test Accuracy 0.4803±0.1086(std)\n",
      " Final best | test F1 0.4304±0.1010(std)\n",
      " Final best | AUROC 0.8460±0.0266(std)\n",
      " Final best | AUPRC 0.5521±0.0699(std)\n",
      "Edgepred_Gprompt GCN GPF-plus  Graph Task completed\n",
      "Final Accuracy 0.4803±0.1086(std)\n",
      "Final F1 0.4304±0.1010(std)\n",
      "Final AUROC 0.8460±0.0266(std)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if args.task == 'NodeTask':\n",
    "    data, input_dim, output_dim = load4node(args.dataset_name)   \n",
    "    data = data.to(args.device)\n",
    "    if args.prompt_type in ['Gprompt', 'All-in-one', 'GPF', 'GPF-plus']:\n",
    "        graphs_list = load_induced_graph(args.dataset_name, data, args.device) \n",
    "    else:\n",
    "        graphs_list = None \n",
    "         \n",
    "\n",
    "if args.task == 'GraphTask':\n",
    "    input_dim, output_dim, dataset = load4graph(args.dataset_name)\n",
    "\n",
    "if args.task == 'NodeTask':\n",
    "    tasker = NodeTask(pre_train_model_path = args.pre_train_model_path, \n",
    "                    dataset_name = args.dataset_name, num_layer = args.num_layer,\n",
    "                    gnn_type = args.gnn_type, hid_dim = args.hid_dim, prompt_type = args.prompt_type,\n",
    "                    epochs = args.epochs, shot_num = args.shot_num, device=args.device, lr = args.lr, wd = args.decay,\n",
    "                    batch_size = args.batch_size, data = data, input_dim = input_dim, output_dim = output_dim, graphs_list = graphs_list)\n",
    "\n",
    "\n",
    "if args.task == 'GraphTask':\n",
    "    tasker = GraphTask(pre_train_model_path = args.pre_train_model_path, \n",
    "                    dataset_name = args.dataset_name, num_layer = args.num_layer, gnn_type = args.gnn_type, hid_dim = args.hid_dim, prompt_type = args.prompt_type, epochs = args.epochs,\n",
    "                    shot_num = args.shot_num, device=args.device, lr = args.lr, wd = args.decay,\n",
    "                    batch_size = args.batch_size, dataset = dataset, input_dim = input_dim, output_dim = output_dim)\n",
    "pre_train_type = tasker.pre_train_type\n",
    "\n",
    "\n",
    "_, test_acc, std_test_acc, f1, std_f1, roc, std_roc, _, _= tasker.run()\n",
    "  \n",
    "print(\"Final Accuracy {:.4f}±{:.4f}(std)\".format(test_acc, std_test_acc)) \n",
    "print(\"Final F1 {:.4f}±{:.4f}(std)\".format(f1,std_f1)) \n",
    "print(\"Final AUROC {:.4f}±{:.4f}(std)\".format(roc, std_roc)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
